---
title: "dplyr and in-database scoring"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(dbplyr)
library(DBI)
library(tibble)
library(rlang)
library(purrr)
```

## Motivation

Even if the capability to run models inside the database would be available today, R users may still elect to fit the model locally in R with samples. Running `predict()` may be an entirely different story. It is more likely that predictions need to be run over the entire data set.

The idea is to use the same approach as `dbplot` of using `dplyr` and `rlang` to create a generic formula that can then be translated to SQL appropriate syntax.

## Parse an R model

The `score()` function decomposes the model variables and builds a `dplyr` formula. The `score()` function uses the modelâ€™s `class` to use the correct parser.

```{r}
source("tidymodel.R")

score <- function(model){
  UseMethod("score")
}

score.lm <- function(model){
  
  mt <- tidymodel(model) %>%
    mutate(sym_labels = syms(labels))
  
  coefs <- filter(mt, type == "categorical") 
  part1 <- map2(coefs$sym_labels, coefs$vals, 
                function(name, val) expr((!!name) == (!!val)))
  f <- map2(part1, coefs$estimate, 
            function(name, est) expr(ifelse(!!name, (!!est), 0)))
  
  coefs <- filter(mt, type == "continuous") 
  f <- c(f,map2(coefs$sym_labels, coefs$estimate, 
                function(name, val) expr((!!name) * (!!val))))
  
  intercept <- filter(mt, labels == "(Intercept)")
  
  if(nrow(intercept) > 0){
    f <- c(f, intercept$estimate)
  }
  
  
  reduce(f, function(l, r) expr((!!l) + (!!r)))
  
}

```

## Save results (w/o importing them into memory)

The `db_update()` function sends uses the `UPDATE` clause to apply the formula created in `score()`. This enables the entire calculation and recording the new values exclusively inside the database.  The function uses the `sql_translate()` command to translate the `dplyr` formula into a vendor appropriate SQL statement:


```{r}
db_update <- function(con, table, data, model, prediction_var = NULL ) {
  UseMethod("db_update")
}

db_update.DBIConnection <- function(con, table, data, model, prediction_var = NULL ) {
  
  f <- score(model)
  
  dbSendQuery(con, build_sql("UPDATE ", table ," SET ", prediction_var, " = ", translate_sql(!!f, con = con)))

}
```

## Quick demo

## R


```{r}
df <- tibble(
  x = c(1, 2, 3, 4, 5, 6, 7, 8 , 9),
  y = c(1.1, 2.5, 3.5, 4.75, 5.25, 6.55, 7.66, 8.2, 10),
  z = c("a", "a", "a", "b", "a", "a", "b", "b", "b"),
  score = c(0,0,0,0,0,0,0,0,0)
)
```

### `lm` Model


```{r}
model <- lm(y ~ x + z, df)
summary(model)
```

### `score()`

The `score()` function can be used in-place of `predict()`.  It breaks down the model data to create a formula that can be parsed by `dplyr`, and thus can be potentially parsed by any database that has a `dplyr` translation:

```{r}
score(model)
```

## Database


Open an RSQLite connection:

```{r}
con <- dbConnect(RSQLite::SQLite(), path = ":memory:")
dbWriteTable(con, "df", df)

  
```


Run `db_update()` to save the new results inside the `score` field.  


```{r}
db_update(con, "df", tbl(con, "df"), model, "score")
```

```{r, warning = FALSE}
tbl(con, "df")
```

The results from `predict()` are the exact same as those returned by `score()`

```{r}
predict(model, df)
```

## Further utility: local data

The `score()` function can be called inside a `dplyr` verb, so it can also be used with local data:

```{r}

df %>%
  mutate(prediction = !! score(model))

```




