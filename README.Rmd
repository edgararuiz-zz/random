---
title: "dplyr and in-database scoring"
output:
  github_document:
    toc: true
    toc_depth: 3
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(dbplyr)
library(DBI)
library(tibble)
library(rlang)
library(purrr)
```



## Motivation

Even if the capability to run models inside the database would be available today, R users may still elect to fit the model locally in R with samples. Running `predict()` may be an entirely different story. It is more likely that predictions need to be run over the entire data set.

The idea is to use the same approach as `dbplot` of using `dplyr` and `rlang` to create a generic formula that can then be translated to SQL appropriate syntax.

## Functions

### Parse an R model

The `score()` function decomposes the model variables and builds a `dplyr` formula. The `score()` function uses the modelâ€™s `class` to use the correct parser.

```{r}
source("parsemodel.R")
source("model.R")
```


### Save results (w/o importing them into memory)

The `db_update()` function sends uses the `UPDATE` clause to apply the formula created in `score()`. This enables the entire calculation and recording the new values exclusively inside the database.  The function uses the `sql_translate()` command to translate the `dplyr` formula into a vendor appropriate SQL statement:


```{r}
db_update <- function(con, table, data, model, prediction_var = NULL ) {
  UseMethod("db_update")
}

db_update.DBIConnection <- function(con, table, data, model, prediction_var = NULL ) {
  
  f <- score(model)
  
  dbSendQuery(con, build_sql("UPDATE ", table ," SET ", prediction_var, " = ", translate_sql(!!f, con = con)))

}
```

## Quick demo

### Local data


```{r}
df <- tibble(
  x = c(1, 2, 3, 4, 5, 6, 7, 8 , 9),
  y = c(1.1, 2.5, 3.5, 4.75, 5.25, 6.55, 7.66, 8.2, 10),
  z = c("a", "a", "a", "b", "a", "a", "b", "b", "b"),
  score = c(0,0,0,0,0,0,0,0,0)
)
```

### `lm` Model


```{r}
model <- lm(y ~ x + z, df)
summary(model)
```

### `score()`

The `score()` function can be used in-place of `predict()`.  It breaks down the model data to create a formula that can be parsed by `dplyr`, and thus can be potentially parsed by any database that has a `dplyr` translation:

```{r}
score(model)
```

### Database


Open an RSQLite connection:

```{r}
con <- dbConnect(RSQLite::SQLite(), path = ":memory:")
dbWriteTable(con, "df", df)

  
```

## `db_update()`

Run `db_update()` to save the new results inside the `score` field.  


```{r}
db_update(con, "df", tbl(con, "df"), model, "score")
```

### Confirm accurracy

```{r, warning = FALSE}
tbl(con, "df")
```

The results from `predict()` are the exact same as those returned by `score()`

```{r}
predict(model, df)
```


## `parsemodel()`

The `parsemodel()` function makes a quick tidy table from the model.  This helps simplify the`socre()` code.  The source code is inside the `tidymodel.R` script.

```{r}
parsemodel(model)
```

## `prediction_to_column()`

The `score()` function can be called inside a `dplyr` verb, so it can also be used with local data.  A function similar to `tibble::rowid_to_column`, currently called `prediction_to_column()` can be used with a local `data.frame` to easily add a column with the fitted values.

```{r}

df %>%
  prediction_to_column(model)

```


## More tests

General tests to confirm that the calculations match the base `predict()` calculation.

```{r}

source("model.R")
source("parsemodel.R")



df <- mtcars %>%
  mutate(cyl = paste0("cyl", cyl))

m1 <- lm(mpg ~ wt + am, weights = cyl, data = mtcars)
m2 <- lm(mpg ~ wt + am, data = mtcars)
m3 <- lm(mpg ~ wt + am, offset = cyl, data = mtcars)
m4 <- lm(mpg ~ wt + cyl, data = df)
m5 <- glm(am ~ wt + mpg, data = mtcars)
m6 <- glm(am ~ cyl + mpg, data = df)


a1 <- as.numeric(predict(m1, mtcars))
a2 <- as.numeric(predict(m2, mtcars))
a3 <- as.numeric(predict(m3, mtcars))
a4 <- as.numeric(predict(m4, df))
a5 <- as.numeric(predict(m5, df))
a6 <- as.numeric(predict(m6, df))


b1 <- prediction_to_column(mtcars, m1) %>% pull()
b2 <- prediction_to_column(mtcars, m2) %>% pull()
b3 <- prediction_to_column(mtcars, m3) %>% pull()
b4 <- prediction_to_column(df, m4) %>% pull()
b5 <- prediction_to_column(df, m5) %>% pull()
b6 <- prediction_to_column(df, m6) %>% pull()



sum(a1 - b1 > 0.0000000000001)
sum(a2 - b2 > 0.0000000000001)
sum(a3 - b3 > 0.0000000000001)
sum(a4 - b4 > 0.0000000000001)
sum(a6 - b6 > 0.0000000000001) 

```

## Prediction intervals

The source code for the `prediction_interval()` function is found in the `intervals.R` script.

```{r}
source("intervals.R")

model <- m4


df <- mtcars %>%
  mutate(cyl = paste0("cyl", cyl))

head(df) %>%
  mutate(fit = !!score(model),
         interval = !!prediction_interval(model, 0.95)) %>%
  mutate(lwr = fit - interval,
         upr = fit + interval) %>%
  select(fit, lwr, upr)


head(df) %>%
  predict(model, ., interval = "prediction")
```

